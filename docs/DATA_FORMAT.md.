# NPZ data format specification

All experiments in this repository consume a single NumPy archive (`.npz`) containing arrays aligned by observation index `i = 0, â€¦, n-1`.

## Required arrays

### `X`
- **Shape:** `(n, d)`
- **Type:** float
- **Meaning:** amplitude / feature vector per observation (e.g., log-resistivity, IP chargeability, SP, seismic attributes).
- **Notes:** these values enter the likelihood (data term). Apply any preprocessing (log, robust scaling) before saving, or use the preprocessing flags in the experiment scripts if provided.

### `S`
- **Shape:** `(n, 2)`
- **Type:** float
- **Meaning:** spatial coordinates `(x, y)` in any consistent planar coordinate system. Convention: `x` = easting/horizontal, `y` = northing/vertical. Units should be consistent (typically meters for geophysical applications).
- **Notes:** for ERT or gridded data, ensure coordinates align with the survey geometry.

## Optional arrays

### `anchors`
- **Shape:** `(m,)`
- **Type:** int
- **Meaning:** 0-based indices of anchor observations (high-confidence points).
- **Constraints:** values must be in `[0, n-1]` and unique.

### `y_anchor` (optional)
- **Shape:** `(m,)`
- **Type:** int
- **Meaning:** labels for the anchors, used only for anchor-based diagnostics (e.g., leave-one-anchor-out).
- **Notes:** the clustering method itself does **not** require `y_anchor` unless you evaluate such diagnostics.

### `constraints` (optional)
- **Shape:** `(q, 4)`
- **Type:** float (recommended); cast columns `(i, j, type)` to int after loading
- **Row format:** `(i, j, type, rho)`
  - `i`, `j`: integer indices in `[0, n-1]`
  - `type`: `1` = must-link, `0` = cannot-link
  - `rho`: credibility in `[0, 1]` (if unknown, set to `1.0` and let the method downweight via node credibility if configured)
  - When loading, use: `i = int(row[0])`, `j = int(row[1])`, `type = int(row[2])`, `rho = float(row[3])`
- **Notes:**
  - Constraints are treated *softly* in the objective (violations are allowed with a credibility-weighted cost).
  - Avoid providing contradictory constraints unless your experiment explicitly tests robustness.

## Conventions

- All arrays must align by observation index (rows of `X` correspond to rows of `S`).
- Missing optional arrays disable the corresponding component deterministically.
- Indices are **0-based** throughout (Python convention).

## Minimal example

```python
import numpy as np

n, d = 100, 3
X = np.random.randn(n, d).astype(float)
S = np.random.randn(n, 2).astype(float)

anchors = np.array([0, 10, 42], dtype=int)
y_anchor = np.array([0, 1, 2], dtype=int)

constraints = np.array([
    [0, 10, 1, 1.0],   # must-link
    [10, 42, 0, 0.8],  # cannot-link (credibility 0.8)
], dtype=float)

np.savez("example.npz", X=X, S=S, anchors=anchors, y_anchor=y_anchor, constraints=constraints)

# Loading
data = np.load("example.npz")
X_loaded = data["X"]
S_loaded = data["S"]

# Constraints require casting
if "constraints" in data:
    C = data["constraints"]
    for row in C:
        i, j, ctype, rho = int(row[0]), int(row[1]), int(row[2]), float(row[3])
        # process constraint...
```
